% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{spscicomp Documentation}
\date{February 13, 2015}
\release{beta}
\author{The Project Group}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}


Contents:


\chapter{Common modules}
\label{common:welcome-to-spscicomp-s-documentation}\label{common::doc}\label{common:common-modules}
Currently there is one common module for all algorithms, namely the data importer module. It provides the following classes for importing numerical data:


\section{common\_data\_importer}
\label{common:common-data-importer}\label{common:module-common_data_importer}\index{common\_data\_importer (module)}\index{CommonBinaryFileDataImporter (class in common\_data\_importer)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonBinaryFileDataImporter}\pysiglinewithargsret{\strong{class }\code{common\_data\_importer.}\bfcode{CommonBinaryFileDataImporter}}{\emph{filename}}{}
Import data from a binary file. The file format should be as generated by numpy.save.
\index{get\_data() (common\_data\_importer.CommonBinaryFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonBinaryFileDataImporter.get_data}\pysiglinewithargsret{\bfcode{get\_data}}{\emph{size}}{}
Return a numpy array of floats where each data point occupies one row of the array. The data is read from
the current position of the pointer onwards. If the pointer reaches the end of the file, an array of all data
points up to the end of the file is returned and the hasMoreData flag is set to False.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{size} -- Number of data points to be returned.

\item[{Returns}] \leavevmode
A numpy array of data points.

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_outData() (common\_data\_importer.CommonBinaryFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonBinaryFileDataImporter.get_outData}\pysiglinewithargsret{\bfcode{get\_outData}}{\emph{size}}{}
Return a numpy array of floats where each data point occupies one row of the array. The data is read from
the current position of the pointer onwards. If the pointer reaches the end of the file, an array of all data
points up to the end of the file is returned and the hasMoreData flag is set to False.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{size} -- Number of data points to be returned.

\item[{Returns}] \leavevmode
A numpy array of data points.

\end{description}\end{quote}

\end{fulllineitems}

\index{has\_more\_data() (common\_data\_importer.CommonBinaryFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonBinaryFileDataImporter.has_more_data}\pysiglinewithargsret{\bfcode{has\_more\_data}}{}{}
Test if the pointer is at the end of the file or not.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
True if there is more data after the pointer, and False if not.

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_file\_input\_stream() (common\_data\_importer.CommonBinaryFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonBinaryFileDataImporter.init_file_input_stream}\pysiglinewithargsret{\bfcode{init\_file\_input\_stream}}{}{}
Create a numpy array object which reads from the binary file using a memmap.

\end{fulllineitems}

\index{rewind() (common\_data\_importer.CommonBinaryFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonBinaryFileDataImporter.rewind}\pysiglinewithargsret{\bfcode{rewind}}{}{}
Reset the file pointer to the beginning and set the hasMoreData flag to True.

\end{fulllineitems}

\index{rewindPatch() (common\_data\_importer.CommonBinaryFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonBinaryFileDataImporter.rewindPatch}\pysiglinewithargsret{\bfcode{rewindPatch}}{}{}
Reset the file pointer to the beginning and set the hasMoreData flag to True.

\end{fulllineitems}

\index{write\_data() (common\_data\_importer.CommonBinaryFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonBinaryFileDataImporter.write_data}\pysiglinewithargsret{\bfcode{write\_data}}{\emph{i\_data}}{}
Assumption: i\_data has same size like data of the last get\_data() call

\end{fulllineitems}


\end{fulllineitems}

\index{CommonDataImporter (class in common\_data\_importer)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonDataImporter}\pysigline{\strong{class }\code{common\_data\_importer.}\bfcode{CommonDataImporter}}
This is an abstract data importer class. Implementations are expected to override the get\_data and has\_more\_data
methods.

\end{fulllineitems}

\index{CommonFileDataImporter (class in common\_data\_importer)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonFileDataImporter}\pysiglinewithargsret{\strong{class }\code{common\_data\_importer.}\bfcode{CommonFileDataImporter}}{\emph{filename}}{}
Import data from a text file. The data structure should be as follows:
One point occupies one line.
Each point consists of several floats with space as a separator.
\index{close\_file() (common\_data\_importer.CommonFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonFileDataImporter.close_file}\pysiglinewithargsret{\bfcode{close\_file}}{}{}
Close the file handle if it is open.

\end{fulllineitems}

\index{get\_data() (common\_data\_importer.CommonFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonFileDataImporter.get_data}\pysiglinewithargsret{\bfcode{get\_data}}{\emph{size}}{}
Return a numpy array of floats where each data point occupies one row of the array. The data is read from
the current position of the pointer onwards. If the pointer reaches the end of the file, an array of all data
points up to the end of the file is returned, the file is closed and the hasMoreData flag is set to False.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{size} -- Number of data points to be returned.

\item[{Returns}] \leavevmode
A numpy array of data points.

\end{description}\end{quote}

\end{fulllineitems}

\index{has\_more\_data() (common\_data\_importer.CommonFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonFileDataImporter.has_more_data}\pysiglinewithargsret{\bfcode{has\_more\_data}}{}{}
Test if the pointer is at the end of the file or not.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
True if there is more data after the pointer, and False if not.

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_file\_input\_stream() (common\_data\_importer.CommonFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonFileDataImporter.init_file_input_stream}\pysiglinewithargsret{\bfcode{init\_file\_input\_stream}}{}{}
Initialize the file input stream, that is, open the file and create the iterator on the file's lines.

\end{fulllineitems}

\index{rewind() (common\_data\_importer.CommonFileDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonFileDataImporter.rewind}\pysiglinewithargsret{\bfcode{rewind}}{}{}
Reset the file pointer to the beginning, that is, initialize the file and set the hasMoreData flag to True.

\end{fulllineitems}


\end{fulllineitems}

\index{CommonSimpleDataImporter (class in common\_data\_importer)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonSimpleDataImporter}\pysiglinewithargsret{\strong{class }\code{common\_data\_importer.}\bfcode{CommonSimpleDataImporter}}{\emph{data}}{}
``Import'' data from a given data array.
\index{get\_data() (common\_data\_importer.CommonSimpleDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonSimpleDataImporter.get_data}\pysiglinewithargsret{\bfcode{get\_data}}{\emph{size}}{}
Return all available data regardless of the requested size.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{size} -- Size of data which is to be returned. This parameter is disregarded as all data is returned.

\item[{Returns}] \leavevmode
All data.

\end{description}\end{quote}

\end{fulllineitems}

\index{has\_more\_data() (common\_data\_importer.CommonSimpleDataImporter method)}

\begin{fulllineitems}
\phantomsection\label{common:common_data_importer.CommonSimpleDataImporter.has_more_data}\pysiglinewithargsret{\bfcode{has\_more\_data}}{}{}
Return if there is any more data. As all data is returned when using get\_data, this function always returns False.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
False since there never is any more data.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{The k-means algorithm}
\label{kmeans::doc}\label{kmeans:the-k-means-algorithm}
The implementation of the k-means algorithm consists of the following modules:


\section{kmeans\_main}
\label{kmeans:module-kmeans_main}\label{kmeans:kmeans-main}\index{kmeans\_main (module)}\index{kmeans() (in module kmeans\_main)}

\begin{fulllineitems}
\phantomsection\label{kmeans:kmeans_main.kmeans}\pysiglinewithargsret{\code{kmeans\_main.}\bfcode{kmeans}}{\emph{k}, \emph{importer=None}}{}
Initialize and run the k-means algorithm. If any of the optimized implementations (CUDA, OpenCL, C extension) are
available, they are selected and initialized automatically in the above order. Then the respective
\code{kmeans.Kmeans.calculate\_centers()} method is called and the output is returned.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{k} (\emph{int}) -- Number of cluster centers to compute.

\item {} 
\textbf{importer} ({\hyperref[common:common_data_importer.CommonDataImporter]{\code{CommonDataImporter}}}) -- A {\hyperref[common:common_data_importer.CommonDataImporter]{\code{CommonDataImporter}}} object to be used for importing the numerical data.

\end{itemize}

\item[{Returns}] \leavevmode
An array of integers \([c(x_i)]\) where \(x_i\) is the i-th data point and
\(c(x_i)\) is the index of the cluster center to which \(x_i\) belongs.

\item[{Return type}] \leavevmode
int{[}{]}

\end{description}\end{quote}

\end{fulllineitems}



\section{kmeans}
\label{kmeans:module-kmeans}\label{kmeans:kmeans}\index{kmeans (module)}\index{DefaultKmeans (class in kmeans)}

\begin{fulllineitems}
\phantomsection\label{kmeans:kmeans.DefaultKmeans}\pysiglinewithargsret{\strong{class }\code{kmeans.}\bfcode{DefaultKmeans}}{\emph{metric=\textless{}spscicomp.kmeans.kmeans\_metric.EuclideanMetric object at 0x7f24d5fe96d0\textgreater{}}, \emph{importer=None}, \emph{chunk\_size=1000}, \emph{max\_steps=100}}{}
Default implementation of the k-means algorithm. Once supplied with an {\hyperref[common:common_data_importer.CommonDataImporter]{\code{CommonDataImporter}}} object, use the
calculate\_centers method to compute k cluster centers.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{metric} (\code{KmeansMetric}) -- A \code{KmeansMetric} object to be used for calculating distances between points. The default is
the \code{EuclideanMetric}.

\item {} 
\textbf{importer} ({\hyperref[common:common_data_importer.CommonDataImporter]{\code{CommonDataImporter}}}) -- A {\hyperref[common:common_data_importer.CommonDataImporter]{\code{CommonDataImporter}}} object to be used for importing the numerical data.

\item {} 
\textbf{chunk\_size} (\emph{int}) -- The number of data points to be imported and processed at a time.

\item {} 
\textbf{max\_steps} (\emph{int}) -- The maximum number of steps to run the algorithm for. If the iteration did not converge after
this number of steps, the algorithm is terminated and the last result returned.

\end{itemize}

\end{description}\end{quote}
\index{calculate\_centers() (kmeans.DefaultKmeans method)}

\begin{fulllineitems}
\phantomsection\label{kmeans:kmeans.DefaultKmeans.calculate_centers}\pysiglinewithargsret{\bfcode{calculate\_centers}}{\emph{k}, \emph{initial\_centers=None}, \emph{return\_centers=False}, \emph{save\_history=False}}{}
Main method of the k-means algorithm. Computes k cluster centers from the data supplied by a
{\hyperref[common:common_data_importer.CommonDataImporter]{\code{CommonDataImporter}}} object.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{k} (\emph{int}) -- Number of cluster centers to compute.

\item {} 
\textbf{initial\_centers} (\emph{numpy.array}) -- Array of cluster centers to start the iteration with. If omitted, random data points
from the first chunk of data are used.

\item {} 
\textbf{return\_centers} (\emph{bool}) -- If set to True then the cluster centers are returned.

\item {} 
\textbf{save\_history} (\emph{bool}) -- If this and return\_centers is set to True then the cluster centers in each iteration step
are returned.

\end{itemize}

\item[{Returns}] \leavevmode
An array of integers \([c(x_i)]\) where \(x_i\) is the i-th data point and
\(c(x_i)\) is the index of the cluster center to which \(x_i\) belongs.

\item[{Return type}] \leavevmode
int{[}{]}

\item[{Returns}] \leavevmode
An array of the computed cluster centers.

\item[{Return type}] \leavevmode
np.array

\item[{Returns}] \leavevmode
A list of arrays of the cluster centers in each iteration step.

\item[{Return type}] \leavevmode
np.array{[}{]}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{Kmeans (class in kmeans)}

\begin{fulllineitems}
\phantomsection\label{kmeans:kmeans.Kmeans}\pysiglinewithargsret{\strong{class }\code{kmeans.}\bfcode{Kmeans}}{\emph{metric=\textless{}spscicomp.kmeans.kmeans\_metric.EuclideanMetric object at 0x7f24d5fe90d0\textgreater{}}, \emph{importer=None}}{}
Abstract k-means algorithm. Implementations are expected to override the calculate\_centers method.

\end{fulllineitems}



\section{c\_kmeans}
\label{kmeans:module-spscicomp.kmeans.extension.c_kmeans}\label{kmeans:c-kmeans}\index{spscicomp.kmeans.extension.c\_kmeans (module)}\index{CKmeans (class in spscicomp.kmeans.extension.c\_kmeans)}

\begin{fulllineitems}
\phantomsection\label{kmeans:spscicomp.kmeans.extension.c_kmeans.CKmeans}\pysiglinewithargsret{\strong{class }\code{spscicomp.kmeans.extension.c\_kmeans.}\bfcode{CKmeans}}{\emph{metric=\textless{}spscicomp.kmeans.kmeans\_metric.EuclideanMetric object at 0x7f24d5f04f10\textgreater{}}, \emph{importer=None}, \emph{chunk\_size=1000}, \emph{max\_steps=100}}{}
An implementation of the k-means algorithm in C. Refer to the {\hyperref[kmeans:kmeans.DefaultKmeans]{\code{DefaultKmeans}}} class for parameters and
public methods.

\end{fulllineitems}

\index{cal\_chunk\_centers (C function)}

\begin{fulllineitems}
\phantomsection\label{kmeans:c.cal_chunk_centers}\pysiglinewithargsret{static PyObject* \bfcode{cal\_chunk\_centers}}{PyObject\emph{ *dummy}, PyObject\emph{ *args}}{}
Main function of the C extension.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{args} (\emph{PyObject*}) -- Pointer to parameters transported from Python.

\item {} 
\textbf{dummy} (\emph{PyObject*}) -- Not used here.

\end{itemize}

\item[{Returns}] \leavevmode
The new chunk centers.

\item[{Return type}] \leavevmode
PyObject*

\item[{Raises TypeError}] \leavevmode
Python Arguments parse error!

\end{description}\end{quote}

\end{fulllineitems}

\index{initkmeans\_c\_extension (C function)}

\begin{fulllineitems}
\phantomsection\label{kmeans:c.initkmeans_c_extension}\pysiglinewithargsret{void \bfcode{initkmeans\_c\_extension}}{}{}
Initialize the extension module

\end{fulllineitems}

\index{kmeans\_c\_extensionMethods (C variable)}

\begin{fulllineitems}
\phantomsection\label{kmeans:c.kmeans_c_extensionMethods}\pysigline{PyMethodDef \bfcode{kmeans\_c\_extensionMethods}}
Variable which stores the maps between functions in C and Python

\end{fulllineitems}

\index{closest\_center (C function)}

\begin{fulllineitems}
\phantomsection\label{kmeans:c.closest_center}\pysiglinewithargsret{int \bfcode{closest\_center}}{PyArrayObject\emph{ *data}, int\emph{ data\_lab}, PyArrayObject\emph{ *centers}, int\emph{ cluster\_size}, int\emph{ dimension}}{}
Given the centers and one point and return which center is nearest to the point.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{data} (\emph{PyArrayObject*}) -- One point with related dimension.

\item {} 
\textbf{data\_lab} (\emph{int}) -- Index of the point.

\item {} 
\textbf{centers} (\emph{PyArrayObject*}) -- Current centers.

\item {} 
\textbf{cluster\_size} (\emph{int}) -- Number of clusters.

\item {} 
\textbf{dimension} (\emph{int}) -- Dimension of each point and center.

\end{itemize}

\item[{Returns}] \leavevmode
The index of the nearest center.

\item[{Return type}] \leavevmode
int

\end{description}\end{quote}

\end{fulllineitems}

\index{kmeans\_chunk\_center (C function)}

\begin{fulllineitems}
\phantomsection\label{kmeans:c.kmeans_chunk_center}\pysiglinewithargsret{PyObject* \bfcode{kmeans\_chunk\_center}}{PyArrayObject\emph{ *data}, PyArrayObject\emph{ *centers}, PyObject\emph{ *data\_assigns}}{}
Record the nearest center of each point and renew the centers.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{data} (\emph{PyArrayObject*}) -- Pointer to the point set to be calculated.

\item {} 
\textbf{centers} (\emph{PyArrayObject*}) -- Current centers.

\item {} 
\textbf{data\_assigns} (\emph{PyObject*}) -- For each point record the index of the nearest center.

\end{itemize}

\item[{Returns}] \leavevmode
The updated centers.

\item[{Return type}] \leavevmode
PyObject*

\item[{Raises ValueError}] \leavevmode
Parameters are of the wrong sizes.

\item[{Raises MemoryError}] \leavevmode
RAM allocate error. The imported data chunk may be too large.

\item[{Raises MemoryError}] \leavevmode
RAM release error.

\item[{Raises MemoryError}] \leavevmode
Error occurs when creating a new PyArray

\end{description}\end{quote}

\end{fulllineitems}



\section{cuda\_kmeans}
\label{kmeans:cuda-kmeans}\index{cuda.cuda\_kmeans.CUDAKmeans (class in spscicomp.kmeans.extension.c\_kmeans)}

\begin{fulllineitems}
\phantomsection\label{kmeans:spscicomp.kmeans.extension.c_kmeans.cuda.cuda_kmeans.CUDAKmeans}\pysiglinewithargsret{\strong{class }\code{cuda.cuda\_kmeans.}\bfcode{CUDAKmeans}}{\emph{metric=EuclideanMetric()}, \emph{importer=None}, \emph{chunk\_size=1000}, \emph{max\_steps=100}}{}
An implementation of the k-means algorithm in CUDA. Refer to the {\hyperref[kmeans:kmeans.DefaultKmeans]{\code{DefaultKmeans}}} class for parameters and
public methods.

\end{fulllineitems}

\index{cal\_chunk\_centers (C function)}

\begin{fulllineitems}
\pysiglinewithargsret{static PyObject* \bfcode{cal\_chunk\_centers}}{PyObject\emph{ *dummy}, PyObject\emph{ *args}}{}
Refer to the {\hyperref[kmeans:c.cal_chunk_centers]{\code{cal\_chunk\_centers()}}} in c\_kmeans.

\end{fulllineitems}

\index{initkmeans\_c\_extension\_cuda (C function)}

\begin{fulllineitems}
\phantomsection\label{kmeans:c.initkmeans_c_extension_cuda}\pysiglinewithargsret{void \bfcode{initkmeans\_c\_extension\_cuda}}{}{}
Refer to the {\hyperref[kmeans:c.initkmeans_c_extension]{\code{initkmeans\_c\_extension()}}} in c\_kmeans.

\end{fulllineitems}

\index{kmeans\_c\_extensionMethods (C variable)}

\begin{fulllineitems}
\pysigline{PyMethodDef \bfcode{kmeans\_c\_extensionMethods}}
Refer to the \code{kmeans\_c\_extension\_cudaMethods} in c\_kmeans.

\end{fulllineitems}

\index{chunk\_centers\_sum\_cuda (C function)}

\begin{fulllineitems}
\phantomsection\label{kmeans:c.chunk_centers_sum_cuda}\pysiglinewithargsret{\_global\_\_ void \bfcode{chunk\_centers\_sum\_cuda}}{double\emph{ *cu\_data}, double\emph{ *cu\_centers}, int*\emph{ cu\_centers\_counter}, double*\emph{ cu\_new\_centers}, int*\emph{ cu\_data\_assigns}, int*\emph{ cluster\_size}, int\emph{ *dimension}, int\emph{ *chunk\_size}}{}
Divide the whole data set into several parts, each part is calculated by a Block in cuda.
After calculating the index of the nearest center, select a thread to add up the related centers in one Block.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{cu\_data} (\emph{double*}) -- A chunk of points, which are given pointwise.

\item {} 
\textbf{cu\_centers} (\emph{double*}) -- Current centers.

\item {} 
\textbf{cu\_centers\_counter} (\emph{int*}) -- Count how many points are nearest to a given center, count blockwise.

\item {} 
\textbf{cu\_new\_centers} (\emph{double*}) -- Calculate the sum of the points which are nearest to a given center, add blockwise.

\item {} 
\textbf{cu\_data\_assigns} (\emph{int*}) -- The index of the center which is nearest to a given point.

\item {} 
\textbf{cluster\_size} (\emph{int*}) -- Number of clusters

\item {} 
\textbf{dimension} (\emph{int*}) -- Dimension of the points.

\item {} 
\textbf{chunk\_size} (\emph{int*}) -- Number of points in the chunk.

\end{itemize}

\item[{Return chunk\_centers\_sum\_cuda}] \leavevmode
Summation of nearest centers in one block.

\item[{Return type}] \leavevmode
double*

\end{description}\end{quote}

\end{fulllineitems}

\index{kmeans\_chunk\_center\_cuda (C function)}

\begin{fulllineitems}
\phantomsection\label{kmeans:c.kmeans_chunk_center_cuda}\pysiglinewithargsret{PyObject* \bfcode{kmeans\_chunk\_center\_cuda}}{PyArrayObject\emph{ *data}, PyArrayObject\emph{ *centers}, PyObject\emph{ *data\_assigns}}{}
Record the nearest center of each point and renew the centers.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{data} (\emph{PyArrayObject*}) -- Pointer to the point set to be calculated.

\item {} 
\textbf{centers} (\emph{PyArrayObject*}) -- Current centers.

\item {} 
\textbf{data\_assigns} (\emph{PyObject*}) -- For each point record the index of the nearest center.

\end{itemize}

\item[{Returns}] \leavevmode
The updated centers.

\item[{Return type}] \leavevmode
PyObject*

\item[{Raises Exception}] \leavevmode
No available device detected.

\item[{Raises Exception}] \leavevmode
Compute compacity of the graphic card is not enough.

\item[{Raises Exception}] \leavevmode
Only 1 device is supported currently.

\item[{Raises ValueError}] \leavevmode
Parameters are of the wrong sizes.

\item[{Raises MemoryError}] \leavevmode
RAM allocate Error. The imported data chunk may be too large.

\item[{Raises MemoryError}] \leavevmode
RAM release error.

\item[{Raises MemoryError}] \leavevmode
Graphic card RAM allocate error.

\item[{Raises MemoryError}] \leavevmode
Graphic card RAM release error.

\item[{Raises MemoryError}] \leavevmode
Error occurs when creating a new PyArray

\end{description}\end{quote}

\end{fulllineitems}



\section{opencl\_kmeans}
\label{kmeans:opencl-kmeans}\index{opencl.opencl\_kmeans.OpenCLKmeans (class in spscicomp.kmeans.extension.c\_kmeans)}

\begin{fulllineitems}
\phantomsection\label{kmeans:spscicomp.kmeans.extension.c_kmeans.opencl.opencl_kmeans.OpenCLKmeans}\pysiglinewithargsret{\strong{class }\code{opencl.opencl\_kmeans.}\bfcode{OpenCLKmeans}}{\emph{metric=EuclideanMetric()}, \emph{importer=None}, \emph{chunk\_size=1000}, \emph{max\_steps=100}}{}
An implementation of the k-means algorithm in OpenCL. Refer to the {\hyperref[kmeans:kmeans.DefaultKmeans]{\code{DefaultKmeans}}} class for parameters and
public methods.

\end{fulllineitems}



\section{kmeans\_data\_generator}
\label{kmeans:module-kmeans_data_generator}\label{kmeans:kmeans-data-generator}\index{kmeans\_data\_generator (module)}\index{KmeansDataGenerator (class in kmeans\_data\_generator)}

\begin{fulllineitems}
\phantomsection\label{kmeans:kmeans_data_generator.KmeansDataGenerator}\pysigline{\strong{class }\code{kmeans\_data\_generator.}\bfcode{KmeansDataGenerator}}
Abstract data generator. Implementations are expected to override the generate\_data method.

\end{fulllineitems}

\index{KmeansRandomDataGenerator (class in kmeans\_data\_generator)}

\begin{fulllineitems}
\phantomsection\label{kmeans:kmeans_data_generator.KmeansRandomDataGenerator}\pysiglinewithargsret{\strong{class }\code{kmeans\_data\_generator.}\bfcode{KmeansRandomDataGenerator}}{\emph{size}, \emph{dimension}, \emph{centers\_count}}{}
Generate a test dataset for the k-means algorithm. The centers are generated uniformly.
The other points are produced randomly near one of the centers with normal distribution.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{size} (\emph{int}) -- Number of data points to generate.

\item {} 
\textbf{dimension} (\emph{int}) -- Dimension of the euclidean space the data points will belong to.

\item {} 
\textbf{centers\_count} (\emph{int}) -- Number of cluster centers around which the data points are to be generated.

\end{itemize}

\end{description}\end{quote}
\index{get\_centers() (kmeans\_data\_generator.KmeansRandomDataGenerator method)}

\begin{fulllineitems}
\phantomsection\label{kmeans:kmeans_data_generator.KmeansRandomDataGenerator.get_centers}\pysiglinewithargsret{\bfcode{get\_centers}}{}{}
Return the generated cluster centers.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
A list of numpy arrays representing the cluster centers.

\item[{Return type}] \leavevmode
np.array{[}{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_data() (kmeans\_data\_generator.KmeansRandomDataGenerator method)}

\begin{fulllineitems}
\phantomsection\label{kmeans:kmeans_data_generator.KmeansRandomDataGenerator.get_data}\pysiglinewithargsret{\bfcode{get\_data}}{}{}
Return the generated data points.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
A numpy array of size \emph{size*x*dimension}.

\item[{Return type}] \leavevmode
np.array

\end{description}\end{quote}

\end{fulllineitems}

\index{to\_binary\_file() (kmeans\_data\_generator.KmeansRandomDataGenerator method)}

\begin{fulllineitems}
\phantomsection\label{kmeans:kmeans_data_generator.KmeansRandomDataGenerator.to_binary_file}\pysiglinewithargsret{\bfcode{to\_binary\_file}}{\emph{filename}}{}
Save the generated data to a binary file using \code{numpy.save()} which can be read later using the
respective {\hyperref[common:common_data_importer.CommonDataImporter]{\code{CommonDataImporter}}} object.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{filename} (\emph{str}) -- The file name.

\end{description}\end{quote}

\end{fulllineitems}

\index{to\_file() (kmeans\_data\_generator.KmeansRandomDataGenerator method)}

\begin{fulllineitems}
\phantomsection\label{kmeans:kmeans_data_generator.KmeansRandomDataGenerator.to_file}\pysiglinewithargsret{\bfcode{to\_file}}{\emph{filename}}{}
Save the generated data to a text file using \code{numpy.savetxt()} which can be read later using the
respective {\hyperref[common:common_data_importer.CommonDataImporter]{\code{CommonDataImporter}}} object.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{filename} (\emph{str}) -- The file name.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{The HMM algorithm}
\label{hmm:the-hmm-algorithm}\label{hmm::doc}
The implementation of the Hidden Markov Model algorithm consists of the following modules:


\section{algorithms}
\label{hmm:algorithms}\label{hmm:module-algorithms}\index{algorithms (module)}\index{baum\_welch() (in module algorithms)}

\begin{fulllineitems}
\phantomsection\label{hmm:algorithms.baum_welch}\pysiglinewithargsret{\code{algorithms.}\bfcode{baum\_welch}}{\emph{ob}, \emph{A}, \emph{B}, \emph{pi}, \emph{accuracy=0.001}, \emph{maxit=1000}, \emph{kernel=\textless{}module `spscicomp.hmm.kernel.python' from `/home/florian/PyCharmProjects/spscicomp/hmm/kernel/python.pyc'\textgreater{}}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Perform an optimization iteration with a given initial model.

Locally maximize P(O\textbar{}A,B,pi) in a neighborhood of (A,B,pi) by iterating
\emph{update}. Stops if the probability does not change or the maximal
iteration number is reached.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{ob} (\emph{numpy.array shape (T)}) --
observation sequence

\item {} 
\textbf{A} (\emph{numpy.array shape (N,N)}) --
initial transition matrix

\item {} 
\textbf{B} (\emph{numpy.array shape (N,M)}) --
initial symbol probabilities

\item {} 
\textbf{pi} (\emph{numpy.array shape (N)}) --
initial distribution

\item {} 
\textbf{accuracy} (\emph{float, optional}) --
ending criteria for the iteration

\item {} 
\textbf{maxit} (\emph{int, optional}) --
ending criteria for the iteration

\item {} 
\textbf{kernel} (\emph{module, optional}) --
module containing all functions to make calculations with

\item {} 
\textbf{dtype} (\emph{\{ numpy.float32, numpy.float32 \}, optional}) --
datatype to be used for the matrices.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\textbf{A} (\emph{numpy.array shape (N,N)}) --
new transition matrix

\item {} 
\textbf{B} (\emph{numpy.array shape (N,M)}) --
new symbol probabilities

\item {} 
\textbf{pi} (\emph{numpy.array shape (N)}) --
new initial distribution

\item {} 
\textbf{new\_probability} (\emph{dtype}) --
log P( O \textbar{} A,B,pi )

\item {} 
\textbf{it} (\emph{int}) --
number of iterations done

\end{itemize}


\end{description}\end{quote}


\strong{See also:}


kernel.python, kernel.c, kernel.fortran : possible kernels
baum\_welch\_multiple : perform optimization with multiple observations.



\end{fulllineitems}



\section{kernel}
\label{hmm:kernel}

\subsection{python}
\label{hmm:python}\label{hmm:module-kernel.python}\index{kernel.python (module)}
Python implementation of Hidden Markov Model kernel functions

This module is considered to be the reference for checking correctness of other
kernels. All implementations are being kept very simple, straight forward and
closely related to Rabiners {[}1{]} paper.
\index{backward() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.backward}\pysiglinewithargsret{\code{kernel.python.}\bfcode{backward}}{\emph{A}, \emph{B}, \emph{ob}, \emph{scaling}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Compute all backward coefficients. With scaling!
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{A} (\emph{numpy.array of floating numbers and shape (N,N)}) --
transition matrix of the hidden states

\item {} 
\textbf{B} (\emph{numpy.array of floating numbers and shape (N,M)}) --
symbol probability matrix for each hidden state

\item {} 
\textbf{ob} (\emph{numpy.array of integers and shape (T)}) --
observation sequence of integer between 0 and M, used as indices in B

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{beta} (\emph{np.array of floating numbers and shape (T,N)}) --
beta{[}t,i{]} is the ith forward coefficient of time t. These can be
used in many different algorithms related to HMMs.

\end{description}\end{quote}


\strong{See also:}


backward\_no\_scaling : Compute backward coefficients without scaling



\end{fulllineitems}

\index{backward\_no\_scaling() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.backward_no_scaling}\pysiglinewithargsret{\code{kernel.python.}\bfcode{backward\_no\_scaling}}{\emph{A}, \emph{B}, \emph{ob}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Compute all backward coefficients. No scaling.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{A} (\emph{numpy.array of floating numbers and shape (N,N)}) --
transition matrix of the hidden states

\item {} 
\textbf{B} (\emph{numpy.array of floating numbers and shape (N,M)}) --
symbol probability matrix for each hidden state

\item {} 
\textbf{ob} (\emph{numpy.array of integers and shape (T)}) --
observation sequence of integer between 0 and M, used as indices in B

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{beta} (\emph{np.array of floating numbers and shape (T,N)}) --
beta{[}t,i{]} is the ith backward coefficient of time t

\end{description}\end{quote}


\strong{See also:}


backward : Compute backward coefficients using given scaling factors.



\end{fulllineitems}

\index{draw\_state() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.draw_state}\pysiglinewithargsret{\code{kernel.python.}\bfcode{draw\_state}}{\emph{distr}}{}
helper function for random\_sequence to get the state to a given probability
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{distr} (\emph{array with probabilities where state are the indices})

\item[{Returns}] \leavevmode
\textbf{state} (\emph{integer}) --
which randomly chosen with given distribution

\end{description}\end{quote}

\end{fulllineitems}

\index{forward() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.forward}\pysiglinewithargsret{\code{kernel.python.}\bfcode{forward}}{\emph{A}, \emph{B}, \emph{pi}, \emph{ob}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Compute P(ob\textbar{}A,B,pi) and all forward coefficients. With scaling!
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{A} (\emph{numpy.array of floating numbers and shape (N,N)}) --
transition matrix of the hidden states

\item {} 
\textbf{B} (\emph{numpy.array of floating numbers and shape (N,M)}) --
symbol probability matrix for each hidden state

\item {} 
\textbf{pi} (\emph{numpy.array of floating numbers and shape (N)}) --
initial distribution

\item {} 
\textbf{ob} (\emph{numpy.array of integers and shape (T)}) --
observation sequence of integer between 0 and M, used as indices in B

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\textbf{prob} (\emph{floating number}) --
The probability to observe the sequence \emph{ob} with the model given
by \emph{A}, \emph{B} and \emph{pi}.

\item {} 
\textbf{alpha} (\emph{np.array of floating numbers and shape (T,N)}) --
alpha{[}t,i{]} is the ith forward coefficient of time t. These can be
used in many different algorithms related to HMMs.

\item {} 
\textbf{scaling} (\emph{np.array of floating numbers and shape (T)}) --
scaling factors for each step in the calculation. can be used to
rescale backward coefficients.

\end{itemize}


\end{description}\end{quote}


\strong{See also:}


forward\_no\_scaling : Compute forward coefficients without scaling



\end{fulllineitems}

\index{forward\_no\_scaling() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.forward_no_scaling}\pysiglinewithargsret{\code{kernel.python.}\bfcode{forward\_no\_scaling}}{\emph{A}, \emph{B}, \emph{pi}, \emph{ob}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Compute P(ob\textbar{}A,B,pi) and all forward coefficients. No scaling done.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{A} (\emph{numpy.array of floating numbers and shape (N,N)}) --
transition matrix of the hidden states

\item {} 
\textbf{B} (\emph{numpy.array of floating numbers and shape (N,M)}) --
symbol probability matrix for each hidden state

\item {} 
\textbf{pi} (\emph{numpy.array of floating numbers and shape (N)}) --
initial distribution

\item {} 
\textbf{ob} (\emph{numpy.array of integers and shape (T)}) --
observation sequence of integer between 0 and M, used as indices in B

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\textbf{prob} (\emph{floating number}) --
The probability to observe the sequence \emph{ob} with the model given
by \emph{A}, \emph{B} and \emph{pi}.

\item {} 
\textbf{alpha} (\emph{numpy.array of floating numbers and shape (T,N)}) --
alpha{[}t,i{]} is the ith forward coefficient of time t. These can be
used in many different algorithms related to HMMs.

\end{itemize}


\end{description}\end{quote}


\strong{See also:}


forward : Compute forward coefficients and scaling factors



\end{fulllineitems}

\index{random\_sequence() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.random_sequence}\pysiglinewithargsret{\code{kernel.python.}\bfcode{random\_sequence}}{\emph{A}, \emph{B}, \emph{pi}, \emph{T}}{}
Generate an observation sequence of length T from the model A, B, pi.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{A} (\emph{numpy.array shape (N,N)}) --
transition matrix of the model

\item {} 
\textbf{B} (\emph{numpy.array shape (N,M)}) --
symbol probability matrix of the model

\item {} 
\textbf{pi} (\emph{numpy.array shape (N)}) --
starting probability vector of the model

\item {} 
\textbf{T} (\emph{integer}) --
length of generated observation sequence

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{obs} (\emph{numpy.array shape (T)}) --
observation sequence containing only symbols, i.e. ints in {[}0,M)

\end{description}\end{quote}
\paragraph{Notes}

This function relies on the function draw\_state(distr).


\strong{See also:}

\begin{description}
\item[{draw\_state}] \leavevmode{[}draw the index of the state, obeying the probability{]}
distribution vector distr

\end{description}



\end{fulllineitems}

\index{state\_counts() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.state_counts}\pysiglinewithargsret{\code{kernel.python.}\bfcode{state\_counts}}{\emph{gamma}, \emph{T}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Sum the probabilities of being in state i to time t
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{gamma} (\emph{numpy.array shape (T,N)}) --
gamma{[}t,i{]} is the probabilty at time t to be in state i !

\item {} 
\textbf{T} (\emph{number of observationsymbols})

\item {} 
\textbf{dtype} (\emph{item datatype {[}optional{]}})

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{count} (\emph{numpy.array shape (N)}) --
count{[}i{]} is the summed probabilty to be in state i !

\end{description}\end{quote}
\paragraph{Notes}

This function is independ of alpha and beta being scaled, as long as their
scaling is independ in i.


\strong{See also:}


forward, forward\_no\_scaling : to calculate \emph{alpha}
backward, backward\_no\_scaling : to calculate \emph{beta}



\end{fulllineitems}

\index{state\_probabilities() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.state_probabilities}\pysiglinewithargsret{\code{kernel.python.}\bfcode{state\_probabilities}}{\emph{alpha}, \emph{beta}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Calculate the (T,N)-probabilty matrix for being in state i at time t.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{alpha} (\emph{numpy.array shape (T,N)}) --
forward coefficients

\item {} 
\textbf{beta} (\emph{numpy.array shape (T,N)}) --
backward coefficients

\item {} 
\textbf{dtype} (\emph{item datatype {[}optional{]}})

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{gamma} (\emph{numpy.array shape (T,N)}) --
gamma{[}t,i{]} is the probabilty at time t to be in state i !

\end{description}\end{quote}
\paragraph{Notes}

This function is independ of alpha and beta being scaled, as long as their
scaling is independ in i.


\strong{See also:}


forward, forward\_no\_scaling : to calculate \emph{alpha}
backward, backward\_no\_scaling : to calculate \emph{beta}



\end{fulllineitems}

\index{symbol\_counts() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.symbol_counts}\pysiglinewithargsret{\code{kernel.python.}\bfcode{symbol\_counts}}{\emph{gamma}, \emph{ob}, \emph{M}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Sum the observed probabilities to see symbol k in state i.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{gamma} (\emph{numpy.array shape (T,N)}) --
gamma{[}t,i{]} is the probabilty at time t to be in state i !

\item {} 
\textbf{ob} (\emph{numpy.array shape (T)})

\item {} 
\textbf{M} (\emph{integer. number of possible observationsymbols})

\item {} 
\textbf{dtype} (\emph{item datatype, optional})

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{counts} (\emph{numpy.array shape (N,M)})

\end{description}\end{quote}
\paragraph{Notes}

This function is independ of alpha and beta being scaled, as long as their
scaling is independ in i.


\strong{See also:}


forward, forward\_no\_scaling : to calculate \emph{alpha}
backward, backward\_no\_scaling : to calculate \emph{beta}



\end{fulllineitems}

\index{transition\_counts() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.transition_counts}\pysiglinewithargsret{\code{kernel.python.}\bfcode{transition\_counts}}{\emph{alpha}, \emph{beta}, \emph{A}, \emph{B}, \emph{ob}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Sum for all t the probability to transition from state i to state j.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{alpha} (\emph{numpy.array shape (T,N)}) --
forward coefficients

\item {} 
\textbf{beta} (\emph{numpy.array shape (T,N)}) --
backward coefficients

\item {} 
\textbf{A} (\emph{numpy.array shape (N,N)}) --
transition matrix of the model

\item {} 
\textbf{B} (\emph{numpy.array shape (N,M)}) --
symbol probabilty matrix of the model

\item {} 
\textbf{ob} (\emph{numpy.array shape (T)}) --
observation sequence containing only symbols, i.e. ints in {[}0,M)

\item {} 
\textbf{dtype} (\emph{item datatype {[}optional{]}})

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{counts} (\emph{numpy.array shape (N, N)}) --
counts{[}i, j{]} is the summed probability to transition from i to j
int time {[}0,T)

\end{description}\end{quote}
\paragraph{Notes}

It does not matter if alpha or beta scaled or not, as long as there scaling
does not depend on the second variable.


\strong{See also:}


transition\_probabilities : return the matrix of transition probabilities
forward : calculate forward coefficients \emph{alpha}
backward : calculate backward coefficients \emph{beta}



\end{fulllineitems}

\index{transition\_probabilities() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.transition_probabilities}\pysiglinewithargsret{\code{kernel.python.}\bfcode{transition\_probabilities}}{\emph{alpha}, \emph{beta}, \emph{A}, \emph{B}, \emph{ob}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Compute for each t the probability to transition from state i to state j.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{alpha} (\emph{numpy.array shape (T,N)}) --
forward coefficients

\item {} 
\textbf{beta} (\emph{numpy.array shape (T,N)}) --
backward coefficients

\item {} 
\textbf{A} (\emph{numpy.array shape (N,N)}) --
transition matrix of the model

\item {} 
\textbf{B} (\emph{numpy.array shape (N,M)}) --
symbol probabilty matrix of the model

\item {} 
\textbf{ob} (\emph{numpy.array shape (T)}) --
observation sequence containing only symbols, i.e. ints in {[}0,M)

\item {} 
\textbf{dtype} (\emph{item datatype {[}optional{]}})

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{xi} (\emph{numpy.array shape (T-1, N, N)}) --
xi{[}t, i, j{]} is the probability to transition from i to j at time t.

\end{description}\end{quote}
\paragraph{Notes}

It does not matter if alpha or beta scaled or not, as long as there scaling
does not depend on the second variable.


\strong{See also:}


state\_counts : calculate the probability to be in state i at time t
forward : calculate forward coefficients \emph{alpha}
backward : calculate backward coefficients \emph{beta}



\end{fulllineitems}

\index{update() (in module kernel.python)}

\begin{fulllineitems}
\phantomsection\label{hmm:kernel.python.update}\pysiglinewithargsret{\code{kernel.python.}\bfcode{update}}{\emph{gamma}, \emph{xi}, \emph{ob}, \emph{M}, \emph{dtype=\textless{}type `numpy.float32'\textgreater{}}}{}
Return an updated model for given state and transition counts.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{gamma} (\emph{numpy.array shape (T,N)}) --
state probabilities for each t

\item {} 
\textbf{xi} (\emph{numpy.array shape (T,N,N)}) --
transition probabilities for each t

\item {} 
\textbf{ob} (\emph{numpy.array shape (T)}) --
observation sequence containing only symbols, i.e. ints in {[}0,M)

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\textbf{A} (\emph{numpy.array (N,N)}) --
new transition matrix

\item {} 
\textbf{B} (\emph{numpy.array (N,M)}) --
new symbol probabilities

\item {} 
\textbf{pi} (\emph{numpy.array (N)}) --
new initial distribution

\item {} 
\textbf{dtype} (\emph{\{ nupmy.float64, numpy.float32 \}, optional})

\end{itemize}


\end{description}\end{quote}
\paragraph{Notes}

This function is part of the Baum-Welch algorithm for a single observation.


\strong{See also:}


state\_probabilities : to calculate \emph{gamma}
transition\_probabilities : to calculate \emph{xi}



\end{fulllineitems}



\chapter{The Amuse algorithm}
\label{tica:the-amuse-algorithm}\label{tica::doc}
The implementation of the Amuse algorithm consists of the following modules:


\section{Tica\_Amuse}
\label{tica:tica-amuse}\label{tica:module-Tica_Amuse}\index{Tica\_Amuse (module)}\index{TicaAmuse (class in Tica\_Amuse)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_Amuse.TicaAmuse}\pysiglinewithargsret{\strong{class }\code{Tica\_Amuse.}\bfcode{TicaAmuse}}{\emph{i\_inFileName=None}, \emph{i\_outFileName='../testdata/tica\_independentComp.npy'}, \emph{i\_addEps=1e-09}, \emph{i\_timeLag=1}, \emph{i\_useDampingAdapt=True}}{}
Implementation of AMUSE-Algorithm, which basically uses functionality of {\hyperref[tica:Tica_PrincipleComp.TicaPrinComp]{\code{TicaPrinComp}}}.
A {\hyperref[common:common_data_importer.CommonDataImporter]{\code{CommonDataImporter}}} object to be used for importing the numerical data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{i\_inFileName} (\emph{string}) -- A filename of the binary file which loads the data

\item {} 
\textbf{i\_outFileName} (\emph{string}) -- A filename of the binary file which stored the results.

\item {} 
\textbf{i\_addEps} (\emph{float}) -- A damping parameter to avoid dividing by zero in the normalization part of the amuse algorithm.

\item {} 
\textbf{i\_timeLag} (\emph{int}) -- In this setting the data has time-dependencies where i\_timeLag is some lag constant.

\item {} 
\textbf{i\_useDampingAdapt} -- A Boolean flag to use a method for adapting the damping parameter \emph{i\_addEps}.

\end{itemize}

\end{description}\end{quote}

Default setting is \emph{True}
:type bool
\index{performAmuse() (Tica\_Amuse.TicaAmuse method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_Amuse.TicaAmuse.performAmuse}\pysiglinewithargsret{\bfcode{performAmuse}}{\emph{i\_numDomComp=1}}{}
Runs the AMUSE-Algorithm and stores the results in a binary file with
the stated filename(see above \emph{i\_outFileName}).
Performs the hole algorithm only for one given time-lag.
If needed you can run the method again for another time-lag by setting the time-lag
with the function \code{setTimeLag()}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{i\_numDomComp} (\emph{int}) -- Number of independent components which are needed.

\end{description}\end{quote}

\end{fulllineitems}

\index{setTimeLag() (Tica\_Amuse.TicaAmuse method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_Amuse.TicaAmuse.setTimeLag}\pysiglinewithargsret{\bfcode{setTimeLag}}{\emph{i\_timeLag}}{}
Set the time-lag.
:param i\_timeLag: New time-lag.
:type i\_timeLag: int

\end{fulllineitems}


\end{fulllineitems}



\section{Tica\_PrincipleComp}
\label{tica:tica-principlecomp}\label{tica:module-Tica_PrincipleComp}\index{Tica\_PrincipleComp (module)}\index{TicaPrinComp (class in Tica\_PrincipleComp)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp}\pysiglinewithargsret{\strong{class }\code{Tica\_PrincipleComp.}\bfcode{TicaPrinComp}}{\emph{i\_inFileName=None}, \emph{i\_outFileName='../testdata/tica\_tempOutput.npy'}, \emph{i\_addEpsilon=1e-09}, \emph{i\_timeLag=1}, \emph{i\_useDampingAdapt=True}}{}
Implementation of computation of principle components highly adapted for the amuse algorithm.
The class {\hyperref[tica:Tica_PrincipleComp.TicaPrinComp]{\code{TicaPrinComp}}} contains the subclass {\hyperref[tica:Tica_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged]{\code{TicaPrinCompTimeLagged}}}.
A {\hyperref[common:common_data_importer.CommonDataImporter]{\code{CommonDataImporter}}} object to be used for importing the numerical data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{i\_inFileName} (\emph{string}) -- A filename of the binary file which loads the data

\item {} 
\textbf{i\_outFileName} (\emph{string}) -- A filename of the binary file in which the results are stored

\item {} 
\textbf{i\_addEpsilon} -- A damping parameter to avoid dividing by zero in the normalization part of the amuse algorithm.

\item {} 
\textbf{i\_timeLag} (\emph{int}) -- In this setting the data has time-dependencies where i\_timeLag is some lag constant.

\item {} 
\textbf{i\_useDampingAdapt} -- A Boolean flag to use a method for adapting the damping parameter \emph{i\_addEps}.

\end{itemize}

\end{description}\end{quote}

Default setting is \emph{True}
:type bool
\index{TicaPrinComp.TicaPrinCompTimeLagged (class in Tica\_PrincipleComp)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged}\pysiglinewithargsret{\strong{class }\bfcode{TicaPrinCompTimeLagged}}{\emph{i\_ticaPrinComp}}{}
A subclass contained in {\hyperref[tica:Tica_PrincipleComp.TicaPrinComp]{\code{TicaPrinComp}}}. This class contains the time-lagged relevant implementations
of the AMUSE-Algorithm. Especially it is implemented the computation of the
time-lagged covariance matrix \(C^{\tau}\).
The class {\hyperref[tica:Tica_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged]{\code{TicaPrinCompTimeLagged}}} also performs the transformations, which are leads to the
independent components \(Z\).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{i\_ticaPrinComp} ({\hyperref[tica:Tica_PrincipleComp.TicaPrinComp]{\code{TicaPrinComp}}}) -- A {\hyperref[tica:Tica_PrincipleComp.TicaPrinComp]{\code{TicaPrinComp}}} object as input parameter to indicate the dependencies.

\end{description}\end{quote}
\index{computeCovariance() (Tica\_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged.computeCovariance}\pysiglinewithargsret{\bfcode{computeCovariance}}{}{}
Computes the time-lagged covariance matrix \(C^{\tau}\) with
\(c_{ij}^{\tau} = \frac{1}{N-\tau-1}\sum_{t=1}^{N-\tau}x_{it}x_{jt+\tau}\)

\end{fulllineitems}

\index{computeICs() (Tica\_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged.computeICs}\pysiglinewithargsret{\bfcode{computeICs}}{\emph{i\_numDomComp=1}}{}
Main method in the class {\hyperref[tica:Tica_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged]{\code{TicaPrinCompTimeLagged}}}.
Computes the independent components on the basis of normalized principle components supplied by
{\hyperref[tica:Tica_PrincipleComp.TicaPrinComp]{\code{TicaPrinComp}}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{i\_numDumComp} -- Number of needed independent components.

\end{description}\end{quote}

\end{fulllineitems}

\index{performTransformation() (Tica\_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged.performTransformation}\pysiglinewithargsret{\bfcode{performTransformation}}{\emph{i\_domComp}}{}
Computes the independent components and saves needed components in a output numpy binary file.
:param i\_domComp: Needed components of TICA
:type i\_domComp: int

\end{fulllineitems}

\index{setTimeLag() (Tica\_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged.setTimeLag}\pysiglinewithargsret{\bfcode{setTimeLag}}{\emph{i\_timeLag}}{}
Set a new time-lag value.
:param i\_timeLag:
:type: int

\end{fulllineitems}

\index{symmetrizeCovariance() (Tica\_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.TicaPrinCompTimeLagged.symmetrizeCovariance}\pysiglinewithargsret{\bfcode{symmetrizeCovariance}}{}{}
Symmetrizes the time-lagged covariance matrix \(C^{\tau}\) by
\(C_{sym}^{\tau} = \frac{1}{2} \left[ C^{\tau} + \left( C^{\tau} \right)^{T} \right]\)

\end{fulllineitems}


\end{fulllineitems}

\index{calcNumbOfDomComps() (Tica\_PrincipleComp.TicaPrinComp method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.calcNumbOfDomComps}\pysiglinewithargsret{\code{TicaPrinComp.}\bfcode{calcNumbOfDomComps}}{\emph{i\_amountOfTotalVariance}}{}
\emph{Not used actually!}
This function returns, by a given amount of the total variance, the number of relevant
principle components.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{i\_amountOfTotalVariance} (\emph{float}) -- Amount of total variance.

\end{description}\end{quote}

:return : Return the number of dominant principle components.
:rtype: int

\end{fulllineitems}

\index{computeChunkSize() (Tica\_PrincipleComp.TicaPrinComp method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.computeChunkSize}\pysiglinewithargsret{\code{TicaPrinComp.}\bfcode{computeChunkSize}}{}{}
This function computes in a naive way the chunk size, which is used to load a data chunk from the memory map
of \code{CommonDataImporter}.
If the file size of the input file is greater than the threshold a bisection
of the number of rows of the input file will be performed.

\end{fulllineitems}

\index{computeColMeans() (Tica\_PrincipleComp.TicaPrinComp method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.computeColMeans}\pysiglinewithargsret{\code{TicaPrinComp.}\bfcode{computeColMeans}}{}{}
Computes mean per column of the input data.

\end{fulllineitems}

\index{computeCovariance() (Tica\_PrincipleComp.TicaPrinComp method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.computeCovariance}\pysiglinewithargsret{\code{TicaPrinComp.}\bfcode{computeCovariance}}{}{}
This function computes chunk by chunk the instantaneous covariance matrix \(C\).
If a c-extension is available, then it will used by the flag \emph{use\_extension}

\end{fulllineitems}

\index{computePCs() (Tica\_PrincipleComp.TicaPrinComp method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.computePCs}\pysiglinewithargsret{\code{TicaPrinComp.}\bfcode{computePCs}}{\emph{i\_dataChunk}, \emph{i\_domComp}}{}
This function computes the principle components of the input data \(X\).
Let \(\Gamma\) be the matrix which contains the ordered eigenvectors of the instantaneous
covariance matrix \(C\). The principle components \(Y\) are computed
by \(Y = \Gamma^{T}(X-mean(X))\).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{i\_dataChunk} (\emph{numpy.array}) -- A data chunk as a subset of hole data.

\item {} 
\textbf{i\_domComp} (\emph{int}) -- Number of dominated components which are considered.

\end{itemize}

\item[{Return o\_pc}] \leavevmode
The principle components \(Y\).

\item[{Return type}] \leavevmode
numpy.array

\end{description}\end{quote}

\end{fulllineitems}

\index{naiveDampingParamAdapt() (Tica\_PrincipleComp.TicaPrinComp method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.naiveDampingParamAdapt}\pysiglinewithargsret{\code{TicaPrinComp.}\bfcode{naiveDampingParamAdapt}}{}{}
This function adapts possible singular eigenvalues of the covariance matrix.
This is done in a naive way by adding small constants to the effect that small negative eigenvalues
become positive and eigenvalues which are \emph{nan} will be set on a small not negative number.
:return:

\end{fulllineitems}

\index{normalizePCs() (Tica\_PrincipleComp.TicaPrinComp method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_PrincipleComp.TicaPrinComp.normalizePCs}\pysiglinewithargsret{\code{TicaPrinComp.}\bfcode{normalizePCs}}{\emph{i\_pcsChunk}}{}
This function computes the normalizes the principle components \(Y\) of the input data \(X\).
Let \(\Lambda\) be a diagonal matrix with the ordered eigenvalues of the instantaneous
\#covariance matrix \(C\). The normalized principle components \(\tilde{Y}\) are computed
by \(\tilde{Y} = \Lambda^{-\frac{1}{2}}Y)\).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{i\_pcsChunk} (\emph{numpy.array}) -- A chunk of principle components.

\item[{Return o\_pcNorm}] \leavevmode
The normalized principle components \(\tilde{Y}\).

\item[{Return type}] \leavevmode
numpy.array

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{Tica\_EigenDecomp}
\label{tica:tica-eigendecomp}\label{tica:module-Tica_EigenDecomp}\index{Tica\_EigenDecomp (module)}\index{TicaEigenDecomp (class in Tica\_EigenDecomp)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_EigenDecomp.TicaEigenDecomp}\pysiglinewithargsret{\strong{class }\code{Tica\_EigenDecomp.}\bfcode{TicaEigenDecomp}}{\emph{i\_matrix}}{}
A class that post processes the results of the eigen decomposition of \code{numpy.linalg.eig}.
Performs a reordering of the eigen values and the corresponding eigen vectors.
Here are considered only real eigen values.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{i\_matrix} (\emph{numpy.array{[}{]}}) -- A matrix from which the eigen decomposition will realized.

\end{description}\end{quote}
\index{computeEigenDecomp() (Tica\_EigenDecomp.TicaEigenDecomp method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_EigenDecomp.TicaEigenDecomp.computeEigenDecomp}\pysiglinewithargsret{\bfcode{computeEigenDecomp}}{\emph{i\_matrix}}{}
Performs the eigen decomposition of \code{numpy.linalg} and rearrange(see \code{reorderingEigenV()})
the eigenvalues if they are real.
If the eigenvalues have a imaginary part a warning will logged, the imaginary parts will be set to zero
and the real parts will be rearranged.

\end{fulllineitems}

\index{reorderingEigenV() (Tica\_EigenDecomp.TicaEigenDecomp method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_EigenDecomp.TicaEigenDecomp.reorderingEigenV}\pysiglinewithargsret{\bfcode{reorderingEigenV}}{}{}
Reordering of eigenvalues and corresponding eigenvectors by the largest eigenvalue.
Ordering only for real eigenvalues.

\end{fulllineitems}


\end{fulllineitems}



\section{Tica\_DataImport}
\label{tica:module-Tica_DataImport}\label{tica:tica-dataimport}\index{Tica\_DataImport (module)}\index{TicaDataImport (class in Tica\_DataImport)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_DataImport.TicaDataImport}\pysiglinewithargsret{\strong{class }\code{Tica\_DataImport.}\bfcode{TicaDataImport}}{\emph{i\_fileName}}{}
Simple class which import csv data with the \code{numpy} function \code{numpy.loadtxt()}.
\index{getData() (Tica\_DataImport.TicaDataImport method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_DataImport.TicaDataImport.getData}\pysiglinewithargsret{\bfcode{getData}}{}{}
Return the loaded csv data.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
Return a numpy matrix.

\item[{Return type}] \leavevmode
numpy.matrix

\end{description}\end{quote}

\end{fulllineitems}

\index{readTable() (Tica\_DataImport.TicaDataImport method)}

\begin{fulllineitems}
\phantomsection\label{tica:Tica_DataImport.TicaDataImport.readTable}\pysiglinewithargsret{\bfcode{readTable}}{\emph{i\_fileName}}{}
Read a csv file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{i\_fileName} (\emph{string}) -- A filename of the csv file.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{How to build the documentation}
\label{index:how-to-build-the-documentation}\begin{enumerate}
\item {} 
Merge your code branch into the dev branch.

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} git checkout dev
\PYGZdl{} git merge \PYGZlt{}YOUR BRANCH\PYGZgt{}
\end{Verbatim}

\item {} 
Edit the rst files in docs/ to include your documentation in the code. Python, NumPy and Google style documentation markup is supported.

\item {} 
In the docs/ folder, run the compilation:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} make html
\end{Verbatim}

\item {} 
Commit the documentation changes. Be careful to not include any other changes you may have done, as we will cherry-pick this commit into the GitHub Pages branch.

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} git add docs/
\PYGZdl{} git commit \PYGZhy{}m \PYGZdq{}updated documentation.\PYGZdq{}
\end{Verbatim}

\item {} 
Switch to the gh-pages branch and cherry-pick the commit into this branch.

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} git checkout gh\PYGZhy{}pages
\PYGZdl{} git cherry\PYGZhy{}pick \PYGZlt{}COMMIT ID\PYGZgt{}
\end{Verbatim}

\item {} 
Push!

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} git push
\end{Verbatim}

\end{enumerate}


\chapter{Indices and tables}
\label{index:indices-and-tables}\begin{itemize}
\item {} 
\emph{genindex}

\item {} 
\emph{modindex}

\item {} 
\emph{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{a}
\item {\texttt{algorithms}}, \pageref{hmm:module-algorithms}
\indexspace
\bigletter{c}
\item {\texttt{common\_data\_importer}}, \pageref{common:module-common_data_importer}
\indexspace
\bigletter{k}
\item {\texttt{kernel.python}}, \pageref{hmm:module-kernel.python}
\item {\texttt{kmeans}}, \pageref{kmeans:module-kmeans}
\item {\texttt{kmeans\_data\_generator}}, \pageref{kmeans:module-kmeans_data_generator}
\item {\texttt{kmeans\_main}}, \pageref{kmeans:module-kmeans_main}
\indexspace
\bigletter{s}
\item {\texttt{spscicomp.kmeans.extension.c\_kmeans}}, \pageref{kmeans:module-spscicomp.kmeans.extension.c_kmeans}
\indexspace
\bigletter{t}
\item {\texttt{Tica\_Amuse}}, \pageref{tica:module-Tica_Amuse}
\item {\texttt{Tica\_DataImport}}, \pageref{tica:module-Tica_DataImport}
\item {\texttt{Tica\_EigenDecomp}}, \pageref{tica:module-Tica_EigenDecomp}
\item {\texttt{Tica\_PrincipleComp}}, \pageref{tica:module-Tica_PrincipleComp}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
